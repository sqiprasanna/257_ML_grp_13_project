{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vV-oYScto9iU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt \n",
    "from itertools import chain\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# !pip install xlrd==1.2.0\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "# !pip install xlrd==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bwV565Dla6UU"
   },
   "outputs": [],
   "source": [
    "# ### Source: https://spacy.io/usage/linguistic-features\n",
    "\n",
    "# def spacyPipeline(tweets):\n",
    "#     ps = PorterStemmer()\n",
    "#     nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "#     preprocessed_tweets = []\n",
    "#     for t in tweets:\n",
    "#         doc = nlp(t)\n",
    "#         filtered_tweet = []\n",
    "        \n",
    "#         for token in doc:\n",
    "#             if (not token.is_stop) and token.is_alpha:\n",
    "#                 filtered_tweet.append(ps.stem(str(token)))\n",
    "        \n",
    "#         preprocessed_tweets.append(filtered_tweet)\n",
    "    \n",
    "#     return preprocessed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_words = ['bit', 'ly']\n",
    "STOPWORDS.update(app_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZfcaDsxXqXOf"
   },
   "outputs": [],
   "source": [
    "def generateWordCloud(tweets):\n",
    "    allwords = \" \".join(set(chain.from_iterable(tweets)))\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    stopwords = set(STOPWORDS), \n",
    "                    min_font_size = 10).generate(allwords)\n",
    "\n",
    "    plt.axis(\"off\") \n",
    "#     plt.tight_layout(pad = 0) \n",
    "\n",
    "    plt.figure(figsize = (7, 7), facecolor = 'white', edgecolor='blue') \n",
    "    plt.imshow(wordcloud) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "foDbGAADbBzl"
   },
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweets):\n",
    "    # Convert all to lowercase\n",
    "    tweets = [t.lower() for t in tweets]\n",
    "    \n",
    "    # Process tweets through spaCy pipeline\n",
    "    tweets,indices = spacyPipeline(tweets)\n",
    "    \n",
    "    # Filter out words\n",
    "    tweets = [list(filter(lambda w: w != 'link', t)) for t in tweets]\n",
    "\n",
    "    # Remove words less than length 2\n",
    "#     tweets = [list(filter(lambda w: len(w) > 2, t)) for t in tweets]\n",
    "    \n",
    "#     print(tweets)\n",
    "    return tweets, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus,min_n,max_n, n=None):\n",
    "    vec = CountVectorizer(stop_words=STOPWORDS, ngram_range=(min_n,max_n)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items() if len(word) > 3 and word not in set(STOPWORDS)]\n",
    "    # words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(y_test,predicted):\n",
    "    f, ax = plt.subplots(figsize=(5,3))\n",
    "    sns.heatmap(confusion_matrix(y_test, predicted), annot=True, fmt=\".0f\", ax=ax)\n",
    "    plt.xlabel(\"y_head\")\n",
    "    plt.ylabel(\"y_true\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
