{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vV-oYScto9iU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt \n",
    "from itertools import chain\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "%run ./jlu_preprocessing.ipynb\n",
    "%run ./spk_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzEctOLTgBgG",
    "outputId": "306aba10-e11a-47d3-96f6-c25168859bfa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>existence</th>\n",
       "      <th>existence.confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet existence  \\\n",
       "0  Global warming report urges governments to act...       Yes   \n",
       "1  Fighting poverty and global warming in Africa ...       Yes   \n",
       "2  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "3  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "4  URUGUAY: Tools Needed for Those Most Vulnerabl...       Yes   \n",
       "\n",
       "   existence.confidence  \n",
       "0                1.0000  \n",
       "1                1.0000  \n",
       "2                0.8786  \n",
       "3                1.0000  \n",
       "4                0.8087  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_excel(r'C:/Users/Checkout/Desktop/SJSU/sem1/257-ML/Project/global_warming_tweets.xls')\n",
    "data = pd.read_csv(r'C:/Users/Checkout/Desktop/SJSU/sem1/257-ML/Project/global_warming_tweets_main.csv', engine='python') #encoding = \"cp1252\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['existence'] = data['existence'].fillna('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17      Wait here's an idea: it's natural climate chan...\n",
       "31      @New_federalists  i have it on good auth tht g...\n",
       "32      Illegal war and the myth of global warming|My ...\n",
       "33      the scientific community was scamed by global ...\n",
       "35      40 degrees in NYC. please urinate on next libe...\n",
       "                              ...                        \n",
       "781     Don Blankenship Calls Efforts On Mine Safety R...\n",
       "1006    Don't be swayed by distraction of climate chan...\n",
       "1058    Who Cares About Global Warming?: by Jackie Gin...\n",
       "1071    Don Blankenship Called Safety Regulators \"as S...\n",
       "1072    Coal CEO Calls Mine Safety Rules 'As Silly As ...\n",
       "Name: tweet, Length: 61, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['existence']==\"No\"].tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y          2554\n",
      "neutral    1865\n",
      "N          1053\n",
      "Yes         557\n",
      "No           61\n",
      "Name: existence, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['existence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "jzlH830QEEq7",
    "outputId": "cc28841b-f3b1-44a0-e2f3-4169e3bed3b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5960, 4)\n",
      "Yes        3029\n",
      "neutral    1826\n",
      "No         1105\n",
      "Name: existence, dtype: int64\n",
      "(5960, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>existence</th>\n",
       "      <th>existence.confidence</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet existence  \\\n",
       "0  Global warming report urges governments to act...       Yes   \n",
       "1  Fighting poverty and global warming in Africa ...       Yes   \n",
       "2  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "3  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "4  URUGUAY: Tools Needed for Those Most Vulnerabl...       Yes   \n",
       "\n",
       "   existence.confidence  word_count  \n",
       "0                1.0000          18  \n",
       "1                1.0000           8  \n",
       "2                0.8786          12  \n",
       "3                1.0000          12  \n",
       "4                0.8087          11  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word_count'] = data['tweet'].apply(lambda x: len(x.split(\" \")))\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "data.loc[data['existence'] == 'Y','existence'] = \"Yes\"\n",
    "data.loc[data['existence'] == 'N','existence'] = \"No\"\n",
    "print(data.shape)\n",
    "data.dropna()\n",
    "data.loc[data['existence'] == np.nan,'existence'] = \"No\"\n",
    "print(data['existence'].value_counts())\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDLfweEJaxj8",
    "outputId": "82559558-7c40-49b5-fdf4-bf168f421b15",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Global warming report urges governments to act...\n",
       "1       Fighting poverty and global warming in Africa ...\n",
       "2       Carbon offsets: How a Vatican forest failed to...\n",
       "3       Carbon offsets: How a Vatican forest failed to...\n",
       "4       URUGUAY: Tools Needed for Those Most Vulnerabl...\n",
       "                              ...                        \n",
       "6085    @bloodless_coup \"The phrase 'global warming' s...\n",
       "6086    Virginia to Investigate Global Warming Scienti...\n",
       "6087    Global warming you tube parody you will enjoy ...\n",
       "6088    One-Eyed Golfer: Don't dare tell me about glob...\n",
       "6089    man made global warming a hair brained theory ...\n",
       "Name: tweet, Length: 5960, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Global warming report urges governments to act...\n",
       "1       Fighting poverty and global warming in Africa ...\n",
       "2       Carbon offsets: How a Vatican forest failed to...\n",
       "3       Carbon offsets: How a Vatican forest failed to...\n",
       "4       URUGUAY: Tools Needed for Those Most Vulnerabl...\n",
       "                              ...                        \n",
       "6085    @bloodless_coup \"The phrase 'global warming' s...\n",
       "6086    Virginia to Investigate Global Warming Scienti...\n",
       "6087    Global warming you tube parody you will enjoy ...\n",
       "6088    One-Eyed Golfer: Don't dare tell me about glob...\n",
       "6089    man made global warming a hair brained theory ...\n",
       "Name: tweet, Length: 5960, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data[\"tweet\"]\n",
    "# tweets = tweets.drop_duplicates()\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLzOsEtOkVOK",
    "outputId": "36123f17-73f6-42c8-b54a-7827fb0694ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "preprocessed_tweets,indices = preprocess_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>existence</th>\n",
       "      <th>existence.confidence</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18</td>\n",
       "      <td>government belgium face report hunger urge inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>fight poverty warming global africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>12</td>\n",
       "      <td>carbon reduce forest offset fail vatican warmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12</td>\n",
       "      <td>carbon reduce forest offset fail vatican warmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>11</td>\n",
       "      <td>vulnerable change tool need uruguay climate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet existence  \\\n",
       "0  Global warming report urges governments to act...       Yes   \n",
       "1  Fighting poverty and global warming in Africa ...       Yes   \n",
       "2  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "3  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "4  URUGUAY: Tools Needed for Those Most Vulnerabl...       Yes   \n",
       "\n",
       "   existence.confidence  word_count  \\\n",
       "0                1.0000          18   \n",
       "1                1.0000           8   \n",
       "2                0.8786          12   \n",
       "3                1.0000          12   \n",
       "4                0.8087          11   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0  government belgium face report hunger urge inc...  \n",
       "1                fight poverty warming global africa  \n",
       "2  carbon reduce forest offset fail vatican warmi...  \n",
       "3  carbon reduce forest offset fail vatican warmi...  \n",
       "4        vulnerable change tool need uruguay climate  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepr_tweets = [\" \".join(each) for each in preprocessed_tweets]\n",
    "new_data['cleaned_tweet'] = prepr_tweets\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5544, (5960, 4), (5544, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepr_tweets), data.shape, new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections, numpy\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(new_data['cleaned_tweet'].astype('U'))\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "text_tf = tf.fit_transform(new_data['cleaned_tweet'].astype('U'))\n",
    "# print(text_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet                   0\n",
       "existence               0\n",
       "existence.confidence    0\n",
       "word_count              0\n",
       "cleaned_tweet           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.03273816 0.02203327 ... 0.02147607 0.02021837 0.0164164 ]\n",
      " [0.03273816 1.         0.03854919 ... 0.03757431 0.03537386 0.02872197]\n",
      " [0.02203327 0.03854919 1.         ... 0.02528807 0.02380713 0.01933031]\n",
      " ...\n",
      " [0.02147607 0.03757431 0.02528807 ... 1.         0.02320507 0.01884147]\n",
      " [0.02021837 0.03537386 0.02380713 ... 0.02320507 1.         0.01773806]\n",
      " [0.0164164  0.02872197 0.01933031 ... 0.01884147 0.01773806 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# compute similarity using cosine similarity\n",
    "cos_sim=cosine_similarity(text_tf, text_tf)\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Data Shape: (1109, 5544)\n",
      " Train Data Shape: (4435, 5544)\n"
     ]
    }
   ],
   "source": [
    "# splitting data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cos_sim, new_data['existence'], test_size=0.2, random_state=33)\n",
    "print(\" Test Data Shape:\", X_test.shape)\n",
    "print(\" Train Data Shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Data Positive Sentiments : 588\n",
      " Test Data Negative Sentiments : 198\n",
      " Train Data Positive Sentiments : 2261\n",
      " Train Data Positive Sentiments : 817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Yes        2849\n",
       "neutral    1680\n",
       "No         1015\n",
       "Name: existence, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = (y_test == 'Yes').sum()\n",
    "neg = (y_test == 'No').sum()\n",
    "postrain = (y_train == 'Yes').sum()\n",
    "negtrain = (y_train == 'No').sum()\n",
    "total = pos + neg\n",
    "print(\" Test Data Positive Sentiments :\", pos)\n",
    "print(\" Test Data Negative Sentiments :\",neg)\n",
    "print(\" Train Data Positive Sentiments :\", postrain)\n",
    "print(\" Train Data Positive Sentiments :\",negtrain)\n",
    "new_data['existence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform algoritma KNN\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import precision_score, auc,recall_score, f1_score,roc_curve,confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    svm.SVC(kernel='linear').fit(X_train, y_train),\n",
    "#     LinearSVC().fit(X_train, y_train),\n",
    "    DecisionTreeClassifier().fit(X_train, y_train),\n",
    "    KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "\n",
      "**********SVC***********\n"
     ]
    }
   ],
   "source": [
    "row_index = 0\n",
    "for clf in clfs:\n",
    "    print('===============================================\\n')\n",
    "    print(\"**********{}***********\".format(clf.__class__.__name__))\n",
    "    predicted = clf.predict(X_test)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "    MLA_name = clf.__class__.__name__\n",
    "    MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(clf.score(X_train, y_train), 2)\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round( accuracy_score(y_test,predicted), 2)\n",
    "    MLA_compare.loc[row_index, 'MLA Precision'] = round( precision_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    MLA_compare.loc[row_index, 'MLA Recall'] = round( recall_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    MLA_compare.loc[row_index, 'MLA F1 Score'] = round( f1_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    MLA_compare.loc[row_index, 'error_rate'] = round( 1-accuracy_score(y_test,predicted), 2)\n",
    "    MLA_compare.loc[row_index, 'cross val score'] = cross_val_score(clf, cos_sim,new_data['existence'], cv=10).mean()\n",
    "    row_index+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cos_sim, new_data['existence'], test_size=0.2, random_state=33)\n",
    "print(\" Test Data Shape:\", X_test.shape)\n",
    "print(\" Train Data Shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = RandomUnderSampler(random_state = 21).fit_resample(X_train,y_train)\n",
    "# X_train,y_train = RandomOverSampler(random_state = 21).fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_MLA_columns = []\n",
    "under_MLA_compare = pd.DataFrame(columns = under_MLA_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_clfs = [\n",
    "    svm.SVC(kernel='linear').fit(X_train, y_train),\n",
    "#     LinearSVC(C=0.0001).fit(X_train, y_train),\n",
    "    DecisionTreeClassifier().fit(X_train, y_train),\n",
    "    KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_index = 0\n",
    "for clf in under_clfs:\n",
    "    print('===============================================\\n')\n",
    "    print(\"**********{}***********\".format(clf.__class__.__name__))\n",
    "    predicted = clf.predict(X_test)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "    under_MLA_name = clf.__class__.__name__\n",
    "    under_MLA_compare.loc[row_index,'MLA Name'] = under_MLA_name\n",
    "    under_MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(clf.score(X_train, y_train), 2)\n",
    "    under_MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round( accuracy_score(y_test,predicted), 2)\n",
    "    under_MLA_compare.loc[row_index, 'MLA Precision'] = round( precision_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    under_MLA_compare.loc[row_index, 'MLA Recall'] = round( recall_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    under_MLA_compare.loc[row_index, 'MLA F1 Score'] = round( f1_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    under_MLA_compare.loc[row_index, 'error_rate'] = round( 1-accuracy_score(y_test,predicted), 2)\n",
    "    under_MLA_compare.loc[row_index, 'cross val score'] = cross_val_score(clf, cos_sim,new_data['existence'], cv=10).mean()\n",
    "    row_index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)\n",
    "under_MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cos_sim, new_data['existence'], test_size=0.2, random_state=33)\n",
    "print(\" Test Data Shape:\", X_test.shape)\n",
    "print(\" Train Data Shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain,ytrain = RandomUnderSampler(random_state = 21).fit_resample(X_train,y_train)\n",
    "X_train,y_train = RandomOverSampler(random_state = 21).fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_MLA_columns = []\n",
    "over_MLA_compare = pd.DataFrame(columns = over_MLA_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_clfs = [\n",
    "    svm.SVC(kernel='linear').fit(X_train, y_train),\n",
    "#     LinearSVC(C=0.0001).fit(X_train, y_train),\n",
    "\n",
    "    DecisionTreeClassifier().fit(X_train, y_train),\n",
    "    KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_index = 0\n",
    "for clf in over_clfs:\n",
    "    print('===============================================\\n')\n",
    "    print(\"**********{}***********\".format(clf.__class__.__name__))\n",
    "    predicted = clf.predict(X_test)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "    over_MLA_name = clf.__class__.__name__\n",
    "    over_MLA_compare.loc[row_index,'MLA Name'] = over_MLA_name\n",
    "    over_MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(clf.score(X_train, y_train), 2)\n",
    "    over_MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round( accuracy_score(y_test,predicted), 2)\n",
    "    over_MLA_compare.loc[row_index, 'MLA Precision'] = round( precision_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    over_MLA_compare.loc[row_index, 'MLA Recall'] = round( recall_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    over_MLA_compare.loc[row_index, 'MLA F1 Score'] = round( f1_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    over_MLA_compare.loc[row_index, 'error_rate'] = round( 1-accuracy_score(y_test,predicted), 2)\n",
    "    over_MLA_compare.loc[row_index, 'cross val score'] = cross_val_score(clf, cos_sim,new_data['existence'], cv=10).mean()\n",
    "    row_index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data \n",
    "X_train, X_test, y_train, y_test = train_test_split(cos_sim, new_data['existence'], test_size=0.2, random_state=33)\n",
    "print(\" Test Data Shape:\", X_test.shape)\n",
    "print(\" Train Data Shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(k_neighbors=5)\n",
    "X_train,y_train = oversample.fit_resample(X_train,y_train)\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE_MLA_columns = []\n",
    "SMOTE_MLA_compare = pd.DataFrame(columns = SMOTE_MLA_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_clfs = [\n",
    "    svm.SVC(kernel='linear').fit(X_train, y_train),\n",
    "#     LinearSVC(C=0.0001).fit(X_train, y_train),\n",
    "\n",
    "    DecisionTreeClassifier().fit(X_train, y_train),\n",
    "    KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_index = 0\n",
    "for clf in smote_clfs:\n",
    "    print('===============================================\\n')\n",
    "    print(\"**********{}***********\".format(clf.__class__.__name__))\n",
    "    predicted = clf.predict(X_test)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "    SMOTE_MLA_name = clf.__class__.__name__\n",
    "    SMOTE_MLA_compare.loc[row_index,'MLA Name'] = SMOTE_MLA_name\n",
    "    SMOTE_MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(clf.score(X_train, y_train), 2)\n",
    "    SMOTE_MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round( accuracy_score(y_test,predicted), 2)\n",
    "    SMOTE_MLA_compare.loc[row_index, 'MLA Precision'] = round( precision_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    SMOTE_MLA_compare.loc[row_index, 'MLA Recall'] = round( recall_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    SMOTE_MLA_compare.loc[row_index, 'MLA F1 Score'] = round( f1_score(y_test,predicted, average=\"macro\"), 2)\n",
    "    SMOTE_MLA_compare.loc[row_index, 'error_rate'] = round( 1-accuracy_score(y_test,predicted), 2)\n",
    "    SMOTE_MLA_compare.loc[row_index, 'cross val score'] = cross_val_score(clf, cos_sim,new_data['existence'], cv=10).mean()\n",
    "    row_index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "under_MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE_MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # pickling the vectorizer\n",
    "# pickle.dump(tf, open('vectorizer', 'wb'))\n",
    "# # pickling the model\n",
    "# pickle.dump(clfs[0], open('svm_classifier_89', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
